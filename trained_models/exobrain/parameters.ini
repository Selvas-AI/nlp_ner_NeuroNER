[mode]
train_model = True
use_pretrained_model = False
pretrained_model_folder = ../trained_models/exobrain

[dataset]
dataset_text_folder = ../data/exobrain3
main_evaluation_mode = conll
output_folder = ../output

[ann]
use_character_lstm = True
character_embedding_dimension = 25
character_lstm_hidden_state_dimension = 25
token_pretrained_embedding_filepath = D:\corpus\we\GloVe\v1.0\vectors.txt
token_embedding_dimension = 300
token_lstm_hidden_state_dimension = 100
use_crf = True
lstm_cell_type = lnlstm

[training]
patience = 10
maximum_number_of_epochs = 100
optimizer = adadelta
learning_rate = 0.9
gradient_clipping_value = 5.0
dropout_rate = 0.5
number_of_cpu_threads = 8
number_of_gpus = 1

[advanced]
experiment_name = test
tagging_format = bio
tokenizer = korean
spacylanguage = en
remap_unknown_tokens_to_unk = True
load_only_pretrained_token_embeddings = False
load_all_pretrained_token_embeddings = False
check_for_lowercase = True
check_for_digits_replaced_with_zeros = True
freeze_token_embeddings = False
debug = False
verbose = False
plot_format = pdf
reload_character_embeddings = True
reload_character_lstm = True
reload_token_embeddings = True
reload_token_lstm = True
reload_feedforward = True
reload_crf = True
morpheme_tag_include = True
space_tag_include = True
batch_size = 32
skip_data_compatibility = True

